{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CNN - Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from IPython.display import display\n",
    "params = {'legend.fontsize': 16,\n",
    "          'legend.handlelength': 2,\n",
    "          'figure.figsize': (14,12),\n",
    "          'axes.titlesize': 16,\n",
    "          'axes.labelsize': 16\n",
    "         }\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras models and layers\n",
    "import h5py\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset and One-Hotize the output\n",
    "\n",
    "Notice that the images are reshaped to add a single channel (line 9 & 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(\"X_train original shape\", x_train.shape)\n",
    "print(\"y_train original shape\", y_train.shape)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape (after adding channels):', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Conv2D(32, kernel_size=(3, 3), strides=(1,1), activation='relu', input_shape=input_shape, name=\"Input_Conv2D_1\"))\n",
    "model1.add(Conv2D(64, kernel_size=(3, 3), strides=(1,1), activation='relu', name='Conv2D_2'))\n",
    "model1.add(MaxPooling2D(pool_size=(2, 2), name='MaxPool_2'))\n",
    "model1.add(Dropout(0.25, name='Dropout_2'))\n",
    "model1.add(Flatten(name='Flatten'))\n",
    "model1.add(Dense(128, activation='relu', name='Dense_3'))\n",
    "model1.add(Dropout(0.5, name='Dropout_3'))\n",
    "model1.add(Dense(num_classes, activation='softmax', name='Softmax_Output'))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model1.fit(x_train, y_train,batch_size=batch_size, epochs=epochs,\n",
    "           validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = model1.evaluate(x_test, y_test)\n",
    "print()\n",
    "print('Test accuracy: ', score1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(\"mnist_cnn.h5\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model2 with Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Conv2D(32, kernel_size=(3, 3), strides=(1,1), input_shape=input_shape, name='Input_Conv2D_1', activation='relu'))\n",
    "model2.add(BatchNormalization(axis=-1, name='BatchNorm_1'))\n",
    "\n",
    "model2.add(Conv2D(64, kernel_size=(3, 3), strides=(1,1), activation='relu', name='Conv2D_2'))\n",
    "model2.add(BatchNormalization(axis=-1, name='BatchNorm_2'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2), name='MaxPool_2'))\n",
    "model2.add(Dropout(0.25, name='Dropout_2'))\n",
    "\n",
    "model2.add(Conv2D(64, kernel_size=(3, 3), strides=(1,1), name='Conv2D_3', activation='relu'))\n",
    "model2.add(BatchNormalization(axis=-1, name='BatchNorm_3'))\n",
    "model2.add(MaxPooling2D(pool_size=(2,2), name='MaxPool_3'))\n",
    "\n",
    "model2.add(Flatten(name='Flatten')) # Fully connected layer\n",
    "model2.add(BatchNormalization(name='BatchNorm_Flatten'))\n",
    "\n",
    "model2.add(Dense(128, name='Dense_5', activation='relu'))\n",
    "model2.add(BatchNormalization(name='BatchNorm_5'))\n",
    "model2.add(Dropout(0.5, name='Dropout_5'))\n",
    "\n",
    "model2.add(Dense(num_classes, activation='softmax', name='SoftMax_Output'))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model2.fit(x_train, y_train,batch_size=batch_size, epochs=epochs,\n",
    "           validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score2 = model2.evaluate(x_test, y_test)\n",
    "print()\n",
    "print('Test accuracy: ', score2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save(\"mnist_cnn_batchnorm.h5\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Saved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(\"mnist_cnn_batchnorm.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in loaded_model.layers:\n",
    "    if l.name == 'Input_Conv2D_1':\n",
    "        weights, biases = l.get_weights()\n",
    "        print weights.shape, biases.shape\n",
    "        activations = l.output\n",
    "        print activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot histogram of all the weights from first convolutional layer named `Input_Conv2D_1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(weights.reshape(288))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the weights of `15th` kernel from layer `Input_Conv2D_1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(weights[:,:,:,15].reshape(3,3), cmap='gray')\n",
    "plt.grid('off')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize all kernels from layer `Input_Conv2D_1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=6, ncols=6)\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < weights.shape[3]:\n",
    "        im = ax.imshow(weights[:,:,:,i].reshape(weights.shape[0], weights.shape[1]))\n",
    "    ax.xaxis.set_major_formatter(plt.NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
    "    ax.grid(False)\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.1, 0.05, 0.8])\n",
    "fig.colorbar(im, cax=cbar_ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Activations\n",
    "\n",
    "`get_layer_output` function takes in the inputs from `layer 0` and outputs activation from `layer 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_layer_output = K.function([loaded_model.layers[0].input], [loaded_model.layers[7].output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample number `13` which happens to be a `zero` is provided for activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_num = 13\n",
    "activations = get_layer_output([[x_test[sample_num]]])[0]\n",
    "plt.grid('off')\n",
    "plt.imshow(x_test[sample_num].reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=8, ncols=8)\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < activations.shape[3]:\n",
    "        im = ax.imshow(activations[:,:,:,i].reshape(activations.shape[1], activations.shape[2]))\n",
    "    ax.xaxis.set_major_formatter(plt.NullFormatter())\n",
    "    ax.yaxis.set_major_formatter(plt.NullFormatter())\n",
    "    ax.grid(False)\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.1, 0.05, 0.8])\n",
    "fig.colorbar(im, cax=cbar_ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Assignment 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Retrain the models for longer epochs and test if the accuracy gets better.\n",
    "2. Generate statistics/ROC curves for the predictions using batch normalized model.\n",
    "3. Import pretrained models using the following code. In the below snippet I am using VGG16. Note that if you initialize with `weights=None` the weights will be assigned to random. Use this model to visualize weights and activations as above. HINT: to visualize activations you need to provide a 3 channel image (use google), the image size can be determined from the model. You will also have to crop/rotate etc. MNIST data won't work here.\n",
    "```\n",
    "from keras.applications import mobilenet\n",
    "#Load the model, defaults to pretrained weights from Imagenet\n",
    "mobile_model = mobilenet.MobileNet()\n",
    "# Print summary\n",
    "mobile_model.summary()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
