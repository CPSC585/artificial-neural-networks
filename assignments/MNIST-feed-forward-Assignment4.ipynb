{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")\n",
    "from IPython.display import display\n",
    "params = {'legend.fontsize': 16,\n",
    "          'legend.handlelength': 2,\n",
    "          'figure.figsize': (12,9),\n",
    "          'axes.titlesize': 16,\n",
    "          'axes.labelsize': 16\n",
    "         }\n",
    "plt.rcParams.update(params)\n",
    "# Keras models and layers\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "# Convenience Libraries\n",
    "from functools import partial\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.offline as py\n",
    "from plotly.offline import init_notebook_mode, download_plotlyjs\n",
    "import plotly.graph_objs as go\n",
    "import cufflinks as cf\n",
    "init_notebook_mode(connected=True)\n",
    "# plotly.tools.set_credentials_file(username='vkrishnamani', api_key='uTN0DvhXNYXtzrrmwwpG')\n",
    "cf.set_config_file(offline=True, world_readable=True, theme='pearl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import MNIST hand-written digits database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data is import as a split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the priors for the 10 categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = pd.DataFrame(zip(y_train, y_train), columns=['x', 'y']).groupby('x').count().reset_index()\n",
    "data  = go.Data([go.Bar(y = y_df.y,\n",
    "                        x = y_df.x,\n",
    "                        orientation='v'\n",
    "                       )])\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(\n",
    "        title='Classes',\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Count',\n",
    "    )\n",
    ")\n",
    "fig  = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the data shape and visualize it as an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Shape of training set: \", x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the images are provided as `(28 x 28)` px image and there are 60000 samples in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gray_image = partial(plt.imshow, cmap='gray')\n",
    "plot_gray_image(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape `28 x 28 x` px image by flattening to an array of 784 and converting the pixel values to float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 784)\n",
    "x_test = x_test.reshape(x_test.shape[0], 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "print \"Shape of training set after reshaping:\", x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the pixel values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train /= 255.0\n",
    "x_test /= 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert `y` categorical values to one-hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(x_train.shape[1],), name=\"Hidden1\"))\n",
    "model.add(Dense(num_classes, activation='softmax', name='Softmax_output'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    validation_split=0.1,\n",
    "                    batch_size=100,\n",
    "                    epochs=5,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot training and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(history.history)[['acc', 'val_acc']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalulate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "stats_list = []\n",
    "for i in range(10):\n",
    "    # Calculate ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "    # Calculate area under the curve\n",
    "    roc_auc = [auc(fpr, tpr)] * len(fpr)\n",
    "    classes = [i] * len(fpr)\n",
    "    stats_list += zip(fpr, tpr, roc_auc, classes)\n",
    "stats = pd.DataFrame(stats_list, columns=['fpr', 'tpr', 'auc', 'class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for key, grp in stats.groupby(['class']):\n",
    "    trace = go.Scatter(x = grp.fpr,\n",
    "                       y = grp.tpr,\n",
    "                       name = 'class %d' % key)\n",
    "    data.append(trace)\n",
    "# Edit the layout\n",
    "layout = dict(title = 'Receiver Operating Characterstic',\n",
    "              xaxis = dict(title = 'False Positive Rate',\n",
    "                           range = [0, 0.2]),\n",
    "              yaxis = dict(title = 'True Positive Rate'))\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='styled-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.groupby('class').mean().auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Assignment\n",
    "\n",
    "Do the following for all the below questions\n",
    "```\n",
    "Plot the ROC curves and display AUC for this modified dataset. Write short blurb on what changes do you observe in ROC and AUC.\n",
    "```\n",
    "\n",
    "0. Make the model overfit, where you observe training accuracy increase while your test/validation accuracy continuously decreases per epoch. You can change hyperparameters/parameters/model/data etc. Then add `dropout` layers to the model to see if it helps to prevent overfitting. Call this `model0`\n",
    "1. Remove half the samples of one of the class (your choice) from the training set, thereby changing the priors, while keeping the all samples of that class \"as is\" in the test set. (Make sure that when you take out the image data `X_train` also remove the corresponding `y_train` targets). Call this model `model1` \n",
    "2. Now remove all the image data from a single class from the training set, while still keeping the class in the test dataset. Fit, evaluate, generate statistics on this model. Call this model `model2`.\n",
    "3. Now remove all the samples from removed class in `step 2` from test dataset and then calculate the statistics. How does the new statistics differ from statistics in `step 2`?\n",
    "4. Change the target in the output layer from one-hot encoded vector to representing them as integer values. NOTE: to sucessfully train, you will need to change the model. Write about what you changed and why the change was necessary? Call this `model3`.\n",
    "5. Reduce the size of the dataset, while keeping the percentage of priors more-or-less constant. Call this `model4`\n",
    "\n",
    "```\n",
    "NOTE: For each question create a new section in the jupyter notebook.\n",
    "```\n",
    "\n",
    "# Extra Credit\n",
    "1. Modify the model/do hyperparameter search to get the best accuracy for this dataset. You can get really creative with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
